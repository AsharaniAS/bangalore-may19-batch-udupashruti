{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr75v_UYJjvs"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2sf67VoJjvx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- THE DATA ---\n",
      "x_train shape: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('--- THE DATA ---')\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zewyDcBlJjv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XycQGBSGJjv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHSCXy3JjwA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print('First 5 examples now are: ', y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fUQpMHxJjwE"
   },
   "outputs": [],
   "source": [
    "x_train1 =  x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [],
   "source": [
    "x_test1 =  x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN"
   },
   "outputs": [],
   "source": [
    "x_train1 = x_train1.reshape(x_train1.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05098039],\n",
       "        [0.28627452],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.53333336],\n",
       "        [0.49803922],\n",
       "        [0.24313726],\n",
       "        [0.21176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [0.8       ],\n",
       "        [0.6901961 ],\n",
       "        [0.5254902 ],\n",
       "        [0.5647059 ],\n",
       "        [0.48235294],\n",
       "        [0.09019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.03921569],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.60784316],\n",
       "        [0.9254902 ],\n",
       "        [0.8117647 ],\n",
       "        [0.69803923],\n",
       "        [0.41960785],\n",
       "        [0.6117647 ],\n",
       "        [0.6313726 ],\n",
       "        [0.42745098],\n",
       "        [0.2509804 ],\n",
       "        [0.09019608],\n",
       "        [0.3019608 ],\n",
       "        [0.50980395],\n",
       "        [0.28235295],\n",
       "        [0.05882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.27058825],\n",
       "        [0.8117647 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490197],\n",
       "        [0.84705883],\n",
       "        [0.84705883],\n",
       "        [0.6392157 ],\n",
       "        [0.49803922],\n",
       "        [0.4745098 ],\n",
       "        [0.47843137],\n",
       "        [0.57254905],\n",
       "        [0.5529412 ],\n",
       "        [0.34509805],\n",
       "        [0.6745098 ],\n",
       "        [0.25882354]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.78431374],\n",
       "        [0.9098039 ],\n",
       "        [0.9098039 ],\n",
       "        [0.9137255 ],\n",
       "        [0.8980392 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.84313726],\n",
       "        [0.8352941 ],\n",
       "        [0.6431373 ],\n",
       "        [0.49803922],\n",
       "        [0.48235294],\n",
       "        [0.76862746],\n",
       "        [0.8980392 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7176471 ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.8745098 ],\n",
       "        [0.89411765],\n",
       "        [0.92156863],\n",
       "        [0.8901961 ],\n",
       "        [0.8784314 ],\n",
       "        [0.87058824],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.8745098 ],\n",
       "        [0.9607843 ],\n",
       "        [0.6784314 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.75686276],\n",
       "        [0.89411765],\n",
       "        [0.85490197],\n",
       "        [0.8352941 ],\n",
       "        [0.7764706 ],\n",
       "        [0.7058824 ],\n",
       "        [0.83137256],\n",
       "        [0.8235294 ],\n",
       "        [0.827451  ],\n",
       "        [0.8352941 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9529412 ],\n",
       "        [0.7921569 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.85882354],\n",
       "        [0.8627451 ],\n",
       "        [0.83137256],\n",
       "        [0.85490197],\n",
       "        [0.7529412 ],\n",
       "        [0.6627451 ],\n",
       "        [0.8901961 ],\n",
       "        [0.8156863 ],\n",
       "        [0.85490197],\n",
       "        [0.8784314 ],\n",
       "        [0.83137256],\n",
       "        [0.8862745 ],\n",
       "        [0.77254903],\n",
       "        [0.81960785],\n",
       "        [0.20392157]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.3882353 ],\n",
       "        [0.95686275],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.85490197],\n",
       "        [0.79607844],\n",
       "        [0.7764706 ],\n",
       "        [0.8666667 ],\n",
       "        [0.84313726],\n",
       "        [0.8352941 ],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.9607843 ],\n",
       "        [0.46666667],\n",
       "        [0.654902  ],\n",
       "        [0.21960784]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.9254902 ],\n",
       "        [0.89411765],\n",
       "        [0.9019608 ],\n",
       "        [0.89411765],\n",
       "        [0.9411765 ],\n",
       "        [0.9098039 ],\n",
       "        [0.8352941 ],\n",
       "        [0.85490197],\n",
       "        [0.8745098 ],\n",
       "        [0.91764706],\n",
       "        [0.8509804 ],\n",
       "        [0.8509804 ],\n",
       "        [0.81960785],\n",
       "        [0.36078432],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568628],\n",
       "        [0.02352941],\n",
       "        [0.02745098],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.92941177],\n",
       "        [0.8862745 ],\n",
       "        [0.8509804 ],\n",
       "        [0.8745098 ],\n",
       "        [0.87058824],\n",
       "        [0.85882354],\n",
       "        [0.87058824],\n",
       "        [0.8666667 ],\n",
       "        [0.84705883],\n",
       "        [0.8745098 ],\n",
       "        [0.8980392 ],\n",
       "        [0.84313726],\n",
       "        [0.85490197],\n",
       "        [1.        ],\n",
       "        [0.3019608 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24313726],\n",
       "        [0.5686275 ],\n",
       "        [0.8       ],\n",
       "        [0.89411765],\n",
       "        [0.8117647 ],\n",
       "        [0.8352941 ],\n",
       "        [0.8666667 ],\n",
       "        [0.85490197],\n",
       "        [0.8156863 ],\n",
       "        [0.827451  ],\n",
       "        [0.85490197],\n",
       "        [0.8784314 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85882354],\n",
       "        [0.84313726],\n",
       "        [0.8784314 ],\n",
       "        [0.95686275],\n",
       "        [0.62352943],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.17254902],\n",
       "        [0.32156864],\n",
       "        [0.41960785],\n",
       "        [0.7411765 ],\n",
       "        [0.89411765],\n",
       "        [0.8627451 ],\n",
       "        [0.87058824],\n",
       "        [0.8509804 ],\n",
       "        [0.8862745 ],\n",
       "        [0.78431374],\n",
       "        [0.8039216 ],\n",
       "        [0.827451  ],\n",
       "        [0.9019608 ],\n",
       "        [0.8784314 ],\n",
       "        [0.91764706],\n",
       "        [0.6901961 ],\n",
       "        [0.7372549 ],\n",
       "        [0.98039216],\n",
       "        [0.972549  ],\n",
       "        [0.9137255 ],\n",
       "        [0.93333334],\n",
       "        [0.84313726],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.22352941],\n",
       "        [0.73333335],\n",
       "        [0.8156863 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8156863 ],\n",
       "        [0.8       ],\n",
       "        [0.8392157 ],\n",
       "        [0.8156863 ],\n",
       "        [0.81960785],\n",
       "        [0.78431374],\n",
       "        [0.62352943],\n",
       "        [0.9607843 ],\n",
       "        [0.75686276],\n",
       "        [0.80784315],\n",
       "        [0.8745098 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8666667 ],\n",
       "        [0.91764706],\n",
       "        [0.8666667 ],\n",
       "        [0.827451  ],\n",
       "        [0.8627451 ],\n",
       "        [0.9098039 ],\n",
       "        [0.9647059 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.01176471],\n",
       "        [0.7921569 ],\n",
       "        [0.89411765],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.827451  ],\n",
       "        [0.827451  ],\n",
       "        [0.8392157 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9411765 ],\n",
       "        [0.3137255 ],\n",
       "        [0.5882353 ],\n",
       "        [1.        ],\n",
       "        [0.8980392 ],\n",
       "        [0.8666667 ],\n",
       "        [0.7372549 ],\n",
       "        [0.6039216 ],\n",
       "        [0.7490196 ],\n",
       "        [0.8235294 ],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.87058824],\n",
       "        [0.89411765],\n",
       "        [0.88235295],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.38431373],\n",
       "        [0.9137255 ],\n",
       "        [0.7764706 ],\n",
       "        [0.8235294 ],\n",
       "        [0.87058824],\n",
       "        [0.8980392 ],\n",
       "        [0.8980392 ],\n",
       "        [0.91764706],\n",
       "        [0.9764706 ],\n",
       "        [0.8627451 ],\n",
       "        [0.7607843 ],\n",
       "        [0.84313726],\n",
       "        [0.8509804 ],\n",
       "        [0.94509804],\n",
       "        [0.25490198],\n",
       "        [0.28627452],\n",
       "        [0.41568628],\n",
       "        [0.45882353],\n",
       "        [0.65882355],\n",
       "        [0.85882354],\n",
       "        [0.8666667 ],\n",
       "        [0.84313726],\n",
       "        [0.8509804 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8980392 ],\n",
       "        [0.11372549]],\n",
       "\n",
       "       [[0.29411766],\n",
       "        [0.8       ],\n",
       "        [0.83137256],\n",
       "        [0.8       ],\n",
       "        [0.75686276],\n",
       "        [0.8039216 ],\n",
       "        [0.827451  ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.7254902 ],\n",
       "        [0.77254903],\n",
       "        [0.80784315],\n",
       "        [0.7764706 ],\n",
       "        [0.8352941 ],\n",
       "        [0.9411765 ],\n",
       "        [0.7647059 ],\n",
       "        [0.8901961 ],\n",
       "        [0.9607843 ],\n",
       "        [0.9372549 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490197],\n",
       "        [0.83137256],\n",
       "        [0.81960785],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.8666667 ],\n",
       "        [0.9019608 ],\n",
       "        [0.2627451 ]],\n",
       "\n",
       "       [[0.1882353 ],\n",
       "        [0.79607844],\n",
       "        [0.7176471 ],\n",
       "        [0.7607843 ],\n",
       "        [0.8352941 ],\n",
       "        [0.77254903],\n",
       "        [0.7254902 ],\n",
       "        [0.74509805],\n",
       "        [0.7607843 ],\n",
       "        [0.7529412 ],\n",
       "        [0.7921569 ],\n",
       "        [0.8392157 ],\n",
       "        [0.85882354],\n",
       "        [0.8666667 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9254902 ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.78039217],\n",
       "        [0.80784315],\n",
       "        [0.7294118 ],\n",
       "        [0.70980394],\n",
       "        [0.69411767],\n",
       "        [0.6745098 ],\n",
       "        [0.70980394],\n",
       "        [0.8039216 ],\n",
       "        [0.80784315],\n",
       "        [0.4509804 ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.47843137],\n",
       "        [0.85882354],\n",
       "        [0.75686276],\n",
       "        [0.7019608 ],\n",
       "        [0.67058825],\n",
       "        [0.7176471 ],\n",
       "        [0.76862746],\n",
       "        [0.8       ],\n",
       "        [0.8235294 ],\n",
       "        [0.8352941 ],\n",
       "        [0.8117647 ],\n",
       "        [0.827451  ],\n",
       "        [0.8235294 ],\n",
       "        [0.78431374],\n",
       "        [0.76862746],\n",
       "        [0.7607843 ],\n",
       "        [0.7490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.7490196 ],\n",
       "        [0.7764706 ],\n",
       "        [0.7529412 ],\n",
       "        [0.6901961 ],\n",
       "        [0.6117647 ],\n",
       "        [0.654902  ],\n",
       "        [0.69411767],\n",
       "        [0.8235294 ],\n",
       "        [0.36078432]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.2901961 ],\n",
       "        [0.7411765 ],\n",
       "        [0.83137256],\n",
       "        [0.7490196 ],\n",
       "        [0.6862745 ],\n",
       "        [0.6745098 ],\n",
       "        [0.6862745 ],\n",
       "        [0.70980394],\n",
       "        [0.7254902 ],\n",
       "        [0.7372549 ],\n",
       "        [0.7411765 ],\n",
       "        [0.7372549 ],\n",
       "        [0.75686276],\n",
       "        [0.7764706 ],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.8235294 ],\n",
       "        [0.8235294 ],\n",
       "        [0.827451  ],\n",
       "        [0.7372549 ],\n",
       "        [0.7372549 ],\n",
       "        [0.7607843 ],\n",
       "        [0.7529412 ],\n",
       "        [0.84705883],\n",
       "        [0.6666667 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.25882354],\n",
       "        [0.78431374],\n",
       "        [0.87058824],\n",
       "        [0.92941177],\n",
       "        [0.9372549 ],\n",
       "        [0.9490196 ],\n",
       "        [0.9647059 ],\n",
       "        [0.9529412 ],\n",
       "        [0.95686275],\n",
       "        [0.8666667 ],\n",
       "        [0.8627451 ],\n",
       "        [0.75686276],\n",
       "        [0.7490196 ],\n",
       "        [0.7019608 ],\n",
       "        [0.7137255 ],\n",
       "        [0.7137255 ],\n",
       "        [0.70980394],\n",
       "        [0.6901961 ],\n",
       "        [0.6509804 ],\n",
       "        [0.65882355],\n",
       "        [0.3882353 ],\n",
       "        [0.22745098],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15686275],\n",
       "        [0.23921569],\n",
       "        [0.17254902],\n",
       "        [0.28235295],\n",
       "        [0.16078432],\n",
       "        [0.13725491],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DORCLgSwJjwV"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.3720 - accuracy: 0.8669 - val_loss: 0.2919 - val_accuracy: 0.8912\n",
      "Epoch 2/20\n",
      "  224/60000 [..............................] - ETA: 42s - loss: 0.1848 - accuracy: 0.9196 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.2289 - accuracy: 0.9155 - val_loss: 0.2724 - val_accuracy: 0.8981\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.1642 - accuracy: 0.9388 - val_loss: 0.2419 - val_accuracy: 0.9168\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.1153 - accuracy: 0.9562 - val_loss: 0.2756 - val_accuracy: 0.9157\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.0771 - accuracy: 0.9717 - val_loss: 0.3356 - val_accuracy: 0.9102\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.4003 - val_accuracy: 0.9075\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.4070 - val_accuracy: 0.9132\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.4797 - val_accuracy: 0.9072\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.5423 - val_accuracy: 0.9104\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.6187 - val_accuracy: 0.9078\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.5995 - val_accuracy: 0.9114\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.5843 - val_accuracy: 0.9073\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.6699 - val_accuracy: 0.9099\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.7079 - val_accuracy: 0.9127\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.6795 - val_accuracy: 0.9133\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.6991 - val_accuracy: 0.9123\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.8122 - val_accuracy: 0.9086\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.7631 - val_accuracy: 0.9117\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.7580 - val_accuracy: 0.9108\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.7917 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d7bf35c4e0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train1, y_train, batch_size=32, epochs=20, validation_data=(x_test1, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2hAP94vJjwY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Convolution2D(32, 3, 3))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Flatten())\n",
    "model1.add(Dense(128))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.3942 - accuracy: 0.8583 - val_loss: 0.3054 - val_accuracy: 0.8939\n",
      "Epoch 2/20\n",
      "  896/60000 [..............................] - ETA: 11s - loss: 0.2261 - accuracy: 0.9163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.2572 - accuracy: 0.9055 - val_loss: 0.2501 - val_accuracy: 0.9082\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2096 - accuracy: 0.9226 - val_loss: 0.2490 - val_accuracy: 0.9120\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1785 - accuracy: 0.9331 - val_loss: 0.2239 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1496 - accuracy: 0.9442 - val_loss: 0.2265 - val_accuracy: 0.9195\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1295 - accuracy: 0.9509 - val_loss: 0.2254 - val_accuracy: 0.9240\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1104 - accuracy: 0.9570 - val_loss: 0.2367 - val_accuracy: 0.9228\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0956 - accuracy: 0.9637 - val_loss: 0.2421 - val_accuracy: 0.9268\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0825 - accuracy: 0.9692 - val_loss: 0.2668 - val_accuracy: 0.9241\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0719 - accuracy: 0.9736 - val_loss: 0.2779 - val_accuracy: 0.9220\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0633 - accuracy: 0.9761 - val_loss: 0.2949 - val_accuracy: 0.9241\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0590 - accuracy: 0.9774 - val_loss: 0.2851 - val_accuracy: 0.9253\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.2990 - val_accuracy: 0.9275\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.3440 - val_accuracy: 0.9238\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0459 - accuracy: 0.9832 - val_loss: 0.3436 - val_accuracy: 0.9239\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0412 - accuracy: 0.9849 - val_loss: 0.3692 - val_accuracy: 0.9210\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.3549 - val_accuracy: 0.9268\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 0.3779 - val_accuracy: 0.9256\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0356 - accuracy: 0.9872 - val_loss: 0.3745 - val_accuracy: 0.9294\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.3931 - val_accuracy: 0.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d682e48198>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train1, y_train, batch_size=32, epochs=20, validation_data=(x_test1, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpI1_McYJjwg",
    "outputId": "6722631e-c925-448c-c780-93a3100249bc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train1[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44ZnDdJYJjwn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  24/1875 [..............................] - ETA: 13s - loss: 2.9732 - accuracy: 0.3568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.7996 - accuracy: 0.7073 - val_loss: 0.3861 - val_accuracy: 0.8594\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.5756 - accuracy: 0.7829 - val_loss: 0.3663 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.5143 - accuracy: 0.8088 - val_loss: 0.3281 - val_accuracy: 0.8800\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4795 - accuracy: 0.8226 - val_loss: 0.3222 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.4504 - accuracy: 0.8338 - val_loss: 0.3110 - val_accuracy: 0.8884\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4292 - accuracy: 0.8411 - val_loss: 0.3319 - val_accuracy: 0.8812\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4163 - accuracy: 0.8459 - val_loss: 0.3132 - val_accuracy: 0.8872\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.4054 - accuracy: 0.8515 - val_loss: 0.3106 - val_accuracy: 0.8900\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3922 - accuracy: 0.8561 - val_loss: 0.2952 - val_accuracy: 0.8939\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3839 - accuracy: 0.8580 - val_loss: 0.3029 - val_accuracy: 0.8951\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3771 - accuracy: 0.8620 - val_loss: 0.3397 - val_accuracy: 0.8777\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.3698 - accuracy: 0.8632 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.3664 - accuracy: 0.8655 - val_loss: 0.3086 - val_accuracy: 0.8929\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3620 - accuracy: 0.8683 - val_loss: 0.3188 - val_accuracy: 0.8897\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3511 - accuracy: 0.8709 - val_loss: 0.3014 - val_accuracy: 0.8968\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3509 - accuracy: 0.8708 - val_loss: 0.3415 - val_accuracy: 0.8766\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3458 - accuracy: 0.8733 - val_loss: 0.3091 - val_accuracy: 0.8916\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3463 - accuracy: 0.8724 - val_loss: 0.2979 - val_accuracy: 0.8951\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3380 - accuracy: 0.8777 - val_loss: 0.2843 - val_accuracy: 0.8984\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3352 - accuracy: 0.8760 - val_loss: 0.2922 - val_accuracy: 0.8983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d682ef35c0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(datagen.flow(x_train1, y_train,batch_size=32),samples_per_epoch=x_train1.shape[0],epochs=20,validation_data=(x_test1, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1SrtBEPJjwq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 72us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBwVWNQC2qZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6843241023540497, 0.7418000102043152]\n"
     ]
    }
   ],
   "source": [
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KXqmUDW2rM1"
   },
   "source": [
    "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mja6OgQ3L18"
   },
   "source": [
    "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HzVTPUM3WZJ"
   },
   "source": [
    "### **Import neessary libraries for data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPM558TX4KMb"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6hicLwP4SqY"
   },
   "source": [
    "### **Load CIFAR10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1WzrXd4WNk"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9Pht1ggHuiT"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n28ccU6Hp6s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN3vYYhK4W0u"
   },
   "source": [
    "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJbekTKi4cmM"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-SLtUhC4dK2"
   },
   "source": [
    "### **Prepare/fit the generator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSw8Bv2_4hb0"
   },
   "outputs": [],
   "source": [
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYyF-P8O4jQ8"
   },
   "source": [
    "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXug4z234mwQ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = datagen.flow(x_train[:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
