{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1,\n",
       "       4, 8, 4, 3, 0, 2, 4, 4], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY)\n",
    "testY = tf.keras.utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRVEURVF88P8A0wyYl+ZpGWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60784a5950>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:\n",
      "9 0 0 3 0 2 7 2 5 5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [9,0,0,3,0,2,7,2,5,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 0, 0, 3, 0, 2, 7, 2, 5, 5]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAADuCAYAAADRE7iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXmYVNWZ/98bolFRUVbZG1CUARxABLfEuAtqFKMTdVAzeUad3+gEJzMhykQnycTEJShxEk2iMTELShJBkTGChlURwyKrjezI3rYNAkpc7+8P7dfvea1zvF1d1VVd5/t5Hh/f2/fUrVP33HPu4V2TNE2FEEIIISQmPlPqDhBCCCGENDXcABFCCCEkOrgBIoQQQkh0cANECCGEkOjgBogQQggh0cENECGEEEKigxsgQgghhEQHN0CEEEIIiQ5ugAghhBASHdwAEUIIISQ6PtuQxm3btk2rqqqK1BWSiw0bNkhtbW1S6OuWy1j+7W9/U/nVV19V+fDDD3faHXTQQSonSZJTttfbuXOnyp/73OecdkcccYTKLVq0aGi382bhwoW1aZq2K/R1SzWe7733nnNcW1urcps2bVTeb7/9Gv1db731lso4ziLu82KfiWJRCXPz7bffVnnv3r3OuV27dqmMcwTHVcSdm775JyKyZ88elT/zmY//7d26dWunXbt2BZ8emSjG3CyXdbaYvPvuuyoXYp4Xgqxj2aANUFVVlSxYsCD/XpEGM3jw4KJctxBjiXXk8n3pVFdXq3zDDTeo/A//8A9Ou4EDB6q8//77q/zZz7qP8IoVK1SeNGmSyj179nTajR49WuXDDjusod3OmyRJNhbjuqWamzU1Nc7xr3/9a5WvuuoqlXHDmS+LFy9WeeXKlc65L3/5yyo31SJcznMzK+vXr1d51qxZzrknnnhCZdykXHnllU67QYMGqYzj8thjjzntnn32WZVbtmyp8siRI5121157baa+F5pizM0Y3plbt25VuVOnTiXsycdkHcsGbYBIfIQ2Ob5Nz0svveQcT5gwQWW7KOK/LPFfoGPGjHHa1dXVZezxx/Tu3VvlJUuWOOd++MMfqowv53POOcdp9x//8R8q9+/fv8F9qERwnCZPnuyc+81vfqPyo48+qrL9Vz1uYnHDYrUQqKHYtGmTyhdddJHTDp+jSy+9NPwDIuPPf/6zyvfcc49z7sADD1T5nXfecc4dcMABKm/YsEHlyy67zGm3Y8cOlVHbYf9x0rFjR5VbtWql8p/+9Cen3bhx41Q+88wzVb733nuF+Dn99NNVttq3tm3bqvzAAw+onFU7hZscEZHTTjtN5X379qncrVs3p93UqVNVxk1vuUAfIEIIIYREBzdAhBBCCIkOboAIIYQQEh30ASJBQs7Nu3fvVhkdXq2/DfoRHXzwwc459EHASB4bmYXRRm+88YbKGIFiPxfq+5AhQ1TGyJW5c+c67WbOnKnyKaec4pz73e9+571+JYNjiL4cIiK33367yrfddpvK1mkZ/UbQz8c6pB9yyCEqoz/I8OHDnXbWdyh21q5dq/L48eNVtn5s6L/xwQcfOOcwUqtr164qH3rood7vxTln5zB+Dv2+rK/QiSeeqPLmzZtVRn88EZGxY8d6+xEjOH4YjSkismXLFpXxGbDr8SWXXKIyrm/vv/++0w79w3DOYqSfSHn6/SDUABFCCCEkOrgBIoQQQkh0VJQJDE0tIn4TiFXTPffccyoPGzYs0/VRJWhVuFmx/UWaKplbYxgxYoTKmMSwQ4cOTjv8LVaV6ktCaNvhvcJEbLad7zMh0AyHql0Rt+9z5sxxzmEOoz59+mT6rkoDzVcirjr8+uuvV/l///d/nXaYmDJkAjvuuONU/qd/+ieVMSxbpHTJ88oVNA+F7g2aTWxySZybuMb16NHDaYdmULyGXcPss5Lr2iJuYj0M016+fLnTbsqUKSqff/75Oa8dE5irCfM7ibhrJqYU2b59u9MO5ym6MixdutRph+4KOF42SWa5Qw0QIYQQQqKDGyBCCCGEREdFmcBsFAOqcNesWaPygw8+6LRDEwh6rVtzCEYOhcxeaHqxfcJzoWuETDulYuHChc4xmr0w06itD4Vg1ImIG50QikjBe4X3BiNVLJjZ1pZHwOiiLl265Pwei/0ufI5ijUjB+yjiRp90795dZXt/cNxfe+01lW1mWnyu8Nr2Gctq7oyFr371qypj9mdrDkNztXUN8JUUwSzeIu74ITZazEZs+sDrYz0ynKciNHtZevXqpfK8efOcc/gutHURfeBctOZ/LHmB6zbW62sOUANECCGEkOjgBogQQggh0cENECGEEEKio6J8gEIh1tOnT1f5mWeecdphllMM1bT2zGnTpql8zTXXqBwK+/aFeYu42Wutf0lWe3lTMmPGDOcY7xWGv9rfgv481v585513qozVonFMRNxqxNjO+gqh3wL6ANlMwYsWLVIZq0xbHwkM8bS/Cyvbx+oDFHq+X3/9de859O054ogjVLZzDn2FQlm+m0PaiKYE/RUxs/ITTzzhtBs6dKjK1q8KxwJDrK0PEM4Z9Ju0Y4lzCUPna2pqPL/C9S/BLOPkk2AqDrsu4vxAP1c7ljbcvR7rD4s+dziuoSzh5Qg1QIQQQgiJDm6ACCGEEBIdFWUCs+o8ZP78+SrbLLKoLkT57LPPdtq99NJLKo8ePVrlwYMHO+2w2JzNEPzXv/41Z59OOukkp1292rqcwuH/9Kc/OcdoksD7ZkPJURVui2eiKRFNjDbk/mtf+5rKP//5z1Xu27ev0w5NcXjv2rdv77T793//d5Xvu+8+lVGda69nC/thgc9Vq1ap3Lt3b4mFUPZ1fD7sc4zhzfl8lzV5hVIvxM7Xv/51lceNG+ecw1QF1vyLzzua5ENmDhwHez08FzKbYLFjzMzf3MwrTU0onQfOP3QNQHcCEZGBAweqjPfbpiCwJrZ67Ppe7lADRAghhJDo4AaIEEIIIdHR7E1gIbU4RnstWLBAZatKffPNN1VGUwbKIiLHH3+8ykceeaTKNsJo7ty5Kk+cONE5h6pJjNR44IEHnHb15rxyyqyJxfFE3EgtVLH6ih6KuOptyznnnKPywQcf7JzDwqM/+tGPVMaCrCIiTz75pMqockfVrogbBYZjYu83Rn7ZKDD8/S+88ILKMZnA7LOPY4+RI9YEhvcSz4UyOvtM1SKfLOQZO/js4/P9/PPPO+3+67/+y3sNNHthdKXN5o6Z9HEsbTuMAPWZUOy5Cy64wNuOuKA5y2bxxnmFpmnbDl0K0ExpxwtNXTjnQ+NajlADRAghhJDo4AaIEEIIIdHBDRAhhBBCoqNZ+ADlW+n5lltuUXnbtm3eduj3Eaqa+9xzz6mMPkXW92jQoEEqH3XUUc45vP5PfvITldetW+e0q88ybKttNzXLli1T2Ya1+sKcrb8H+gJgRlnLihUrVLb3HscP/Rbss4E2bTyHPjoWtJ1jxmmRcPZh9H2YPXu2yldffbX3uyqNUFV2lK1vQD7t0JfFtiundBHlgA2DrseGPffs2VPl9evXO+fQhwvXIesLh+1wXKwfH1aND41lt27dcvadhMH12aZ6OeaYY1TG8bLrp00DUk/Ipwifh1AqmnKEGiBCCCGERAc3QIQQQgiJjmZhAsu30OHhhx+uMppQ0HQh4obxoQrQhvii6hDNOrZ/aCrDkHgRV3W4Y8cOlc8991zPrygtd9xxh8o2rBUzxYZCyfG+WVUqmhKxeGZdXZ3TDscF75u9Hn4XZjy1mYcnTJig8s6dO1W2zwZ+zp7DPtnM1bFgzRcYOo1mqZBpK1RQ1Tf3rYmU5AeOg13v0LSBa6Q1y+M8w/kXMoeExtxmbSfZwKLCFl/x0lDYOs49a+rGY5zn+M5tDlADRAghhJDo4AaIEEIIIdHBDRAhhBBCoqNZ+ADlC/qihPwR0LcD7aht2rRx2mFoIdrHbShhKB08fg7t4Js3b879I0oMVqlH3xsRkTVr1qiMJS6sDxCmArAhtEOHDlUZ74dth8c4fjZs0xc2bcOksRwKlq7Asij2u+w4d+rUSeWLLrpIYiTkQ4D33I5naD76QL8D6wNkn03yMXh/7Th07txZ5aVLl3o/h/fbXgPLkOA5W54E11n0FaqtrXXa2crj9Vg/FF+oP3Hvb0NAvx+Urc8W3ntcF22ZqXKHGiBCCCGERAc3QIQQQgiJjmahQ7SmB1TNomrOhnFiVl9U4drwTAzjxHYY5i3imnnQPGZNPng9mw119+7dKvfv319la3qpDw8vdTX4f/3Xf80pi7jh46tXr1b5/vvvd9rNnDlTZZsJGu/BYYcdpjLeQ5H8qgyHMgyjihjH9dhjj3XajR8/vsHfW+nguFvTIt5zVKHnWyUaTSpoArEqfpwnaHrJ1xQQC1VVVSrbscQ5iGPevXt3px2aQzCVhQ2Jxna4Btv1naatxpM1dYxt55u/th3OZzxn35nlDjVAhBBCCIkOboAIIYQQEh3NQtdo1W+oqkUTGGb3FXGzP2OhOBuZhddAU9Srr77qtMOsw5gZ1apsMTLJfhdGPFx//fUqL1682GlXr+7PtxBsU4Aq7iFDhqhsI3SmT5+ush1LvI94723Eh408qcfeH1+RPvweEXcs0WSCUW8kNzi+dqzzVb3XEzJ3I9Zc06pVK5Vp9soOZu4OZWf2RWGK+KPArAkMi6FadwXEmr9Jw8n63rDtcN0NRdHiOKNcU1PToH6WGmqACCGEEBId3AARQgghJDq4ASKEEEJIdDQLHyDrD+KrMtyvXz/nGP0T0C/H2jPR9o02TOtLgCHc2CebjRh9WawdvGvXripjiPU3v/lNp90JJ5wgIuUVVmjtxfi7cUysfwdWjw7d+5D/iC88M198viUYim8J2cEL0afmAv5We0+a6nutTxfx4/OfE3H9PNBPUsSd06Eq3zhn8DPW/7FDhw4qoz9QOa1xlUK+PkC+8PaQrxD6U2K1hOYANUCEEEIIiQ5ugAghhBASHQUzgaGKLFToENuh6iyrmjbEsGHDnGPMwoyF+EJhlqgGtqY3DPf0meFE3P6GikBi8UEM4y1XrJkHxw/p1auXc4wF8rKaM7NmKM1KKPs3EhoH+yyHwoYrmZDZKxQuXcjPhMYiVPwzRkL3AzPTY7ZnEXfNxAzPFlwzMSM3ZlgX8c91O5Y2/Ug9zBCdnZAJLFTg2XeNrKloaAIjhBBCCClzuAEihBBCSHTkrVMMRfMUWlU5e/Zs5/ixxx5T+bnnnlMZs5qKuAVLMWrEqvOwv3gN+xvxGmgOs9cLRTWg6QXbTZw40Wl3wQUXeK9RLviK0qLqXMSNxsP7JuKa0TCqzKpmfREJWTMHh4pn4jViNWs1hNCz7xsne19xnLJGkoVU8niMc4xZocNmQDRf9e3b1znXrVs3lXG+2Hu6Y8cOldHMZYum4ufQ9NaxY0en3ZYtW7z9JX5WrVqlsjXxZy1MHFpbfe3w/YmVDpoD1AARQgghJDq4ASKEEEJIdHADRAghhJDoyNtZJ6uvRF1dnXO8detWldFmiX8XcX1isJ2I61OC9kzre4Ohm506dVLZ2rDR9wTt2bbSNdrBsWr4nj17nHZz5sxR2drfMcwa/V/mzZsnzQ1fOLr9zaGMyaFso752hbBhY5/QByXkLxFTtucQoXucNV1B1ky1+Xw+ayg9cdcqm74CfXhwzcTM7iLu+rdr1y6VrU8m+gfZ9R7BNRgz87dv395px3QHLtXV1Sp36dLFOYf3Ht9jFlwLQ3MM2+F7cvv27U67uXPnqozvzHKBTw0hhBBCooMbIEIIIYRER94msBdeeME5vvXWW1XGQneoEhXxZ321RSjRxGZVrqhyQzWdDb9GlduECRNUPv744512GJKJqt5QVkvM4rx3717nHKofrVkO1Y9YNLW5ZdBsCKjutuPsC4EOmVbywX4ezY94zmaqJp+kEAVQs5o+fSY1O07YJ46h3zy0adMmp93LL7+scs+ePZ1zmBka3QmOPPJIpx2uY+vWrVPZFlDFdTYEZvDHgtE33nij045mL5e//OUvKlvzMz4PIdNhVhO2r2iqfTbuv/9+lWkCI4QQQggpA7gBIoQQQkh0NNgEVq9qHjVqlPN3NHOEioH6siRjlmUR15xlTVsIFtzbuHGjc+6mm27KeQ1Uy4m4mUjRBHb66ac77TBKYvXq1SrbQoFoXrHqeFQd4n2yEQ7NgaxRUaGIQcxYis9KyAQWUtP6ztnMqGhGDZlWEEaBfUgow7PPtBWKzArd13yi/3BNwEK8MeEzD02dOtU5/ru/+zuVbZZ2vHe4tnbu3Nlpt3LlSpXxebCRSOg20KFDB5Xt+ommM8wKjWuuiMhRRx0l5GMwkthWY8B1LWt0Vwici/jc2MhpjAIrR6gBIoQQQkh0cANECCGEkOjgBogQQggh0dEgH6Da2lp5+OGHReST/jYYQolhkTZLsrX31mN9L9COb23JaIPet2+fymhXFhG5+uqrVX788cdVtpXW169fn7PvCxcudNrNmDFDZV8mTBHXn8n6niBop7Xt6sNVQ59vLvgyd4u4PgOh8Eyfnw76W9l2OEbWz8TayOuxaRvIJ8HM6XY8ff4F9u+N9aey44fXs74s5GPQD0dE5Nhjj1XZjiWuPdZHE/H5zYXmMPpa2tB89D3y+SGJ0AfIgqlUbAqCrOHtoTXTBz43+D4WcTND4zNk35mlghogQgghhEQHN0CEEEIIiY4GmcD2228/Dde2Zik0daF6q1u3bt52qEq3WUJbt26tMhbls9dAVaotcormlREjRqjcv39/px2qDtFEZ9V0mMUYTS82FBgLz1kTli/U25oI6gvAhlTPzYWshXPzUdP6TFn2GiETDI6lVeH6PhMzoZDafFToWQmNtS+zN3FN/JjyQ8Q1F2IGZhF3nHEOh+ZIKAWKby2zRVPRbILuDlhhgLiZukXc+2PTquC991VjEHHnbNa0JHjts88+22n3hz/8QWV0KSmXrNDUABFCCCEkOrgBIoQQQkh0NNgEVm/6surNrl27qoyRVFZtiWakdu3a5ZRFXPWrVZ3iOVTh2qKkqI5v06aNylgAUMRV/aLJznrS43dhf61qHtXx9hyqj1HV26pVK6fd4sWLRcQtntpcyZpdNKvJJKuJI5RFGM+her8S7nexCUUm+lTooSzO+WCfFZxzuP4QN8rKrtu4ltpxxfUO1zF0XbCgWcaufb6CtT169HDaYcZn/AxGBouI1NXVqYwuE7Hw0ksvec+F3juheYljjs9DKOM7zr1XXnnFaYfjV11drTJNYIQQQgghJYIbIEIIIYREBzdAhBBCCImOBvkAHXTQQTJgwAARccPKRUR+9atfqdypUyeVsYK6iBuqjj471v6MNktrc0b7MV7PZiRFOyWGWtpQULSJoq3TXg/9l3xh/7YdyiJuiDzaTjFUVeTjrNY203E5kU+Yc76+ID6/n5B/USgMHvuB9vKs/koxg3M1lGG70OHoOGbWJwHnydq1a1UeOHBgQfvQHMF1zM4/XBet/xuuu7hu2XuP6yeui9YPBddJrPI+ePBgp93s2bNVxrXarsfobxSjD9CUKVOc47Zt26ps3xs4Zjhe1m8W5yzeb9sOM3TjOKNfq/3eZcuW5fgVpYUaIEIIIYREBzdAhBBCCImOBpnAkDFjxjjH9aYxEZEf/ehHKlvTDoaPo3nIZgNFVa0Ng/eFU4ay/YbCPdHcFroeguds31ENjKGaIq76EdWFWJRQRGTkyJEiIjJu3DhvH0pN1szNqD4PZZFFbLiuz/xhVfr2c77+Yd/xellNajGzdetW7zkcD19IvEj2jNG+Arl2bqIaHk0BxM1ub9c+XI+XL1/unMO5imk67DXw3ofcGtBdAYuynnfeeU47fC/gNWzmY18R1lhAU6+I+96xpihfShjb7sknn1T5/PPPV/nAAw902qG51GYQ97VbsWKFt12poAaIEEIIIdHBDRAhhBBCooMbIEIIIYRER4N9gOpt8tamP3z48Jzy9OnTnXboO4RV2G2ac7TxW78MDM8Mhd1iRVz0M7CV7NE2jfbMrCHR6OMi4voEWR+Vs846S+U+ffqoXC6pwYuNvR/of4PjZ9vhsc8vxF4DsX4mvnB8hsF/OjhfbIoKvM94L+24ZPW7wnBebGfHHX1PsJwNccsR2ece/UF27drlnMP7jalNrG8Plgxq2bKl97t8WB8SvB4+T3htEZFt27apfPTRR2f6rkoCfXRERGbOnKmynW84X0Llfnz+PKFyT6F2uFb079/f+72lghogQgghhEQHN0CEEEIIiY4Gm8B8YcY+Tj/9dOd43rx5OdutXLnSOUa1ra3KvnnzZpW7d++usjVF2SzUpLBkDQtH9TlWehZxVab4bNnnDNXueM72AY+zVrBGGAb/6QwZMkTlVatWOefQjILqbwuq6HGcst5jNH+IuM9EjOaQEG+++abKNmWHDS1HsDI4rq02/BzXagyrx++17VC24dy+dAf22cCw7xi55pprnONrr71WZWsCQ1OnzeSN+N7vNrUEznN8Nnbv3u20w+NRo0Z5v7dUUANECCGEkOjgBogQQggh0ZF3JuhCc8wxxwSPkX79+hW7O6SAoLrUFtVD0xRmrLWmKIwoyWrOChU5xUhAzHhr1fG+Pog03BxcKaAZ5aqrrnLOzZgxQ+Xa2lqVrTkEzSihgr84bjieVVVVTjs0tVszT+yg2blHjx7OOTRzWfB5x8gha9rECNbx48erbE1lZ5xxRs5r23mF6wWOZc+ePZ12p512mrfvMYLZtW1lAcQW70Zqampy/t1mjMbnBueoNUtOnTpVZXRXKRfiXMEJIYQQEjXcABFCCCEkOrgBIoQQQkh0lI0PEGl+ZK0GP2jQIJX79u3rnMPKzyHfHvQTwGyloSrvvhB7EdfvBH0OMMTbEqvPjwXvsfUHGTZsWM7P1NXVOcfoU4BZ4O14HnHEETnlrCH2TF0gct9996lsM/XivPrKV77inEN/OPTf2LRpk9MO/YoGDx6cqU9f/vKXvecuvfTSTNcgLphp2YbBz5kzR+Xq6mqVbaWGk08+Oee1b7jhBucYfYXwucEqEM0BruiEEEIIiQ5ugAghhBASHYmveGTOxknymohsLF53SA66p2na7tObNQyOZcngeFYOHMvKouDjybEsGZnGskEbIEIIIYSQSoAmMEIIIYREBzdAhBBCCImOit8AJUkyKkmS5UmSrEiS5MZS94c0jiRJzk2S5JUkSdYkSXJTqftD8odjWTkkSXJAkiR/TZJkyUdr7XdL3SeSP7HMzYr2AUqSpJ+IPCoiQ0TkHRF5WkT+X5qmq4MfJGVJkiQtRGSViJwlIptFZL6IXJ6m6csl7RhpMBzLyiL5MOFSyzRN9yZJsp+IPCcio9I0nVfirpEGEtPcrHQNUB8RmZem6Vtpmr4nIrNEZESJ+0TyZ4iIrEnTdF2apu/Ih5vbC0vcJ5IfHMsKIv2Q+krH+330X+X+67qyiWZuVvoGaLmIfCFJkjZJkhwkIsNFpGuJ+0Typ7OIYBrazR/9jTQ/OJYVRpIkLZIkWSwiNSLyTJqmL5a6TyQvopmbFb0BStO0WkTuEJFn5EPz1xIRea+knSKNIVddA/4rs3nCsaww0jR9P03TASLSRUSGfOSCQJof0czNit4AiYikafrLNE0HpWn6BRGpExH6/zRfNourwesiIltL1BfSODiWFUqaprtEZKaInFvirpD8iGZuVvwGKEmS9h/9v5uIXCwij5S2R6QRzBeRo5Ik6ZEkyf4icpmITC5xn0h+cCwriCRJ2iVJcthH8oEicqaIrCxtr0ieRDM3Y6gG/1iSJG1E5F0RuT5N052l7hDJjzRN30uS5AYRmSoiLUTkoTRNV5S4WyQPOJYVR0cRefijCKLPiMgf0jSdUuI+kTyIaW5WdBg8IYQQQkguKt4ERgghhBBi4QaIEEIIIdHBDRAhhBBCooMbIEIIIYREBzdAhBBCCIkOboAIIYQQEh0NygPUtm3btKqqqkhd8fPee271it27d6tcW1urcosWLZx2BxxwgMqf+czHez17vTfffFPlli1bqty5s1v+BK/RVGzYsEFqa2tzpSZvFKUay9hZuHBhbZqm7Qp93XIczz179qj8uc99zjm3//77Z7rG22+/rfJbb72l8uGHH97I3jUezs3Kohhzk2NZGrKOZYM2QFVVVbJgwYIGdcTmGUqShq8XNTU1zvH06dNVfuCBB1Q+7LDDnHZ9+vRRGRfgnTvdXIgvvPCCyieccILKP/jBD5x2Bx54YKb+4m/O5/cigwcPbtTnfeQzlqTxJEmysRjXLcR4+nKC5fsMz5o1S+VevXo557p06ZLpGuvXr1cZf9+ll16aV58KCedmZVGMucmxLA1Zx5ImMEIIIYRER1FKYWTVgKD56sc//rFz7tlnn1X5b3/7m3MOzVTvvPOOyvPnz3faTZw4Mef37rfffs4xmrpefPFFlU866SSnXevWrVU+9dRTVf63f/s3p105qOcJaSg4b0Pm3s2bN6v80EMPOefGjh2rMpqqCwH26corr3TO3XHHHSqPGjUq0/U++OAD7/UJIZUPZzwhhBBCooMbIEIIIYREBzdAhBBCCImOovgAhVi7dq3K559/vspHHHGE0w4juqzPDoa7Y3SXjcrYu3fvp35GxPUjeu2111S24fIYkvvMM8+o/PzzzzvtrrvuOpUvvvhiIaQcyeoDM3DgQOd49erVKuOcEBE56KCDVMY5bf340E8O5/q2bducdvv27VMZozDt9f7zP/9TZYzePOOMM5x248ePV9n+Xrwf9AfyY6MFffct5P/pizj8tM/5mDt3rnOM/puvvPKKyr179270d1UyhY4EzcrIkSNV/sY3vuGcGzRokMq43tj3eD5wlhNCCCEkOrgBIoQQQkh0FMUEFlKX3XzzzSp37NhRZRs6juYne73PfvbjbqPKDk1eIq6KDGU0eYm4maDR3IbfI+Jmlka1r73eT3/6U5XPPvts59zBBx8shJSKrKHuJ554osrLly93znXo0EFl++zjXMVzdi5t375dZTR72WSjmDEazV44F+0xrh2PPPKI0w6zST/++OPOObwfhUxmGhNZ71U+93TmzJnrDO1ZAAAagElEQVTO8bJly1RGs6yIyJgxY1TGsZw2bZrTrhBmlHIh6zMbaofH2C5rQuN3333XOcb3KY7XJZdc4rRbtWqVyvY9jvO00HORGiBCCCGERAc3QIQQQgiJjqJHgdmoDlR9H3rooSpb1RmqzFFtLeKarN5//32VbTFUPEb1to0gwetju1D0GZqyrDoe+zd58mTn3BVXXCGElIqQCnnSpEkqz5s3T+WuXbs67dD8a+ctXt8ni7hzH9XrNjLNZ7Kzcxivj/O2W7duTrupU6eq/Oc//9k5N2zYMG9/YyCrmcP+3a67Pn7zm9+ojDUX58yZ47S79957Ve7UqZPKS5YscdphRBdGComIjBs3TuUBAwZk6l9zx2e+CrXD96cF56KNiEZTNbaz78zZs2erPGLECJVtMeRjjjlGZXQhsdjrNxZqgAghhBASHdwAEUIIISQ6uAEihBBCSHQU3Qdo586dzjH6AKHt2GaURb8ca2PG8Fpf6KqIa5tEu6e1ZyIhOyr6JWHG6LZt23r7h1XtRegDRJqekJ8cglnL8Znes2eP0y6UpR19gkJzDs9lzbocaudbB2yYPvZ9+PDhzjn0V8Qs1rbvNqSffEx1dbXK9r5hGPuCBQtUrqurc9pdffXVKp966qkqWz8fvAbKIq6PyZo1a1Q+8sgjg/2vFLL6sIXWAzwX8r3Bubdp0ybnHM6xQw45RGXrezR27FiVO3fu7JwrZkoKaoAIIYQQEh3cABFCCCEkOoquy126dKlzjGpRNIfZ8Fc8tmHmGBrZq1cvlauqqpx2WJgRw/ZatmzptEP1HpriMHOliMiTTz6Z83q7du1y2mEmSwyJJ6QU+NTcF154oXOM5iFM87BhwwZvO2uW8qnKQ+G2+WC/F1Xj+HvtuoJrgl1X0ERz2WWX5bxeJZPVvGDTkmAhUjQdtmrVymn3ta99TeV77rlHZWvywGKYNTU13v5h6PSiRYucc1isGsc5FhNY1kLHlh07dqiMpsnXX3/dabdw4cKcn7Fmz9atW6uMz8Ybb7zhtLOFzJsKaoAIIYQQEh3cABFCCCEkOopuAkNVsojI5z//eZV///vfq2wLLmIxO1R1hrCq2X379uWUrVkKs8qiecxGbP3whz9U+fjjj1cZTXkirpp93bp1mfpOSFPzwgsveM/ZqEwkpE4PZX9GQplqs5C1iKPtK0ap2WzS8+fPVxnXrViyQlszJd47vAehotO4jtvipT//+c9Vfvrpp1U+55xzvH1q37699xyax9DUIiKyZcsWlR966CGVTz75ZKddv379vNdvzoTGcu3atSrfeOONTjt058CorRUrVjjt0A3l5ZdfVvmLX/yi0w7Nm7im2CK0ocjsrORjZqcGiBBCCCHRwQ0QIYQQQqKDGyBCCCGEREfRfYBGjx7tHKMt8rTTTlN54MCBTrvdu3erbH2A0MaPVaXbtGnjtPNlrLU2fbwehudZvyQMoUT/JQwZtv2wts7YybdKsc8fId8svRgmmjVE1IL+JPi9zcVnBFM5iLhZk0P3EccwlAkarxGyz4fC1n3PSyg0HZ8JG+qOfgg2Hcb48eNVxsy0sRBKLYDY5wbHaPr06SqPHDnSafezn/2ssV10wNBsfF+IiBx33HEqY1Zo69tmw7srhVDmZkwd8+tf/9o5Z9+hDaVdu3bOMfrZob/VV77yFacd+hSF1n48F6rUkBVqgAghhBASHdwAEUIIISQ6im4CsyGOf/nLX1R+7LHHVJ42bZrTDgvi3Xfffc45NFNhoTsbnukzlaCaXsRVkaK6zapwMSzw9ttvV9mauQ4//HCVJ06c6JzDrKk2dDMGspqHrHrT97msak/7DH3/+99XeevWrZmuYQmpmcuVJUuWqIwFfUXczL2ousb5Yc9ZE5Ov8Ko1beG5UOi8rxBiqPAxPhO2HRZntvM29iKnWecmroMiIl/4whdyyhZMRYLPTdZ0CbYdFq/FNVfEdY0YNmxYzs+IiGzcuNH73TFgTV44j3AuZ13r0K1FxH3H4xjNmjXLafetb31L5awFWi35mDOpASKEEEJIdHADRAghhJDo4AaIEEIIIdFRdKP3TTfd5H4h2Nkx9K1Pnz5Ou8mTJ6v8ve99z3t9tE1am77Pz8Da+n3+QbZkBobVDx06VGWscivi2kFt9eEY/X5C+Gz8Wf0xMHRZRGTx4sUq//GPf1TZ+qpguObll1+u8iOPPJLpe0XcsPE777xT5W9/+9uZr9HU4LNu/XIQ9Kez4dE4ZjYNAZ7D61tfHPQvwOuHwuBD9n9fOxtSi+uF/V2bN2/2Xp/4yTqWCJ4LjWsI9GGzqUh8z6H1E43d7yvkaxny+8F5j/fwqquuctrhGozfhb67Iq5/mE2zgGDZjeuvv945h2U3skINECGEEEKigxsgQgghhERH0fV/I0aMcI4xDH7hwoUqY6iiiMiXvvQllbHqr4hIt27dVEb1qw1vR7VaKBMtqvCwkrtVAe7Zs0dlDJ+85557nHZ4zlZExozXNvt1pRIKZfWFwK5evdo5RlUqVjG36RN69uypcpcuXVS2obsbNmxQ+amnnvJ1Pcijjz6q8osvvpjXNZqaRYsWqYwmPBF/mLkNg0cVtTUT+9Tmdpx9mb2tWQrnbSgDuG9+27/jmmCz1qIZBccTzd3kk/hMWPbv+NyE1uPQeoHgs/fwww87584//3yVr7jiCpWtqSxkbomBfLPW+7Ln430XcUPfsdI8pikQcfcFXbt2dc7ZPUQ9mNJCxHWHwEoNIagBIoQQQkh0cANECCGEkOgougmsurraOUYTE0ZPnXDCCU67559/XuVly5Y551BtF4o08GWYDRXk9EU02P6iWnXAgAFOux49eqhs1XlHH32097vLkVDRUDShWDMJElKzolp0zJgxKk+YMMFph4UrO3bsqPKQIUOcdmgGfeutt1S2BXW3bNmi8i233OLtH5pfbZ++8Y1vqLxy5UqV0bQr4hZmLDX47Nt5gCaLrJlf7TXwc5gx2ppDfKat0NxE7DOFRS4xo7WN+kHTmf2NeI1x48ap3JDIwHIna4b1YhOK1PO1s2AWY+tOsGDBApWvu+46ldeuXeu0O+mkkz69sxVGVhNjaK3I+tzg+w9dSOrq6px2F1xwgfcaHTp0UBnnrM06je+FrFADRAghhJDo4AaIEEIIIdHBDRAhhBBCoqPoPkDW5or23k2bNqlssymHwtExlBFtkzarp8+fJ1RxGv1G7PeiPwj2z/oZoH8J+riIiGzfvl1lDNkuJ0K2XyTk94NgiCNWBxZxQxcxS3bfvn2ddji2b7zxhsq7d+922mFYK/oNoU+AiPu8YcjkXXfd5b1e//79nXPoM4L+LjbkvpywYcCIr/qzHWd8JkL+G0jIVy8rodB8nGc4v22oP2Zzt33Ca+J4VhKl8vkJkTUTNGZ5FxH5+7//e5Uxm7uIyJQpU1SeOnWqyvZ5sD6aMZDPM+ALe/80lixZovKxxx6r8rZt25x2mFLErum33nqryviuPeuss/LqE0INECGEEEKigxsgQgghhERH0U1g1oSCRSnRrGHNBmiKsuo3VF2jCt5+ly+E27bzFfCz6lI817ZtW/GBIX42Y+3WrVtVLlcTGKpIs6qn7733XpXvv/9+59yOHTtUtirnfv36qYzPA34m1L+QORPH1Wb9tWrWemxY7KRJk7z9+P73v6/yT3/6U5W7d+/utPvd737nvUZT84Mf/EBla+LFYzTv2ZBVDD/OGrZeCHCuWxMYPqfYd5sdHk2AuMaIuGbtxx9/XOVyCR2vJHAsQ2vMHXfcobJ9Dv/lX/5F5d/+9rfOOXxGhw8frjJmgBfJbsaPBV+IvH2P+QqN27mCBcrxHd+QdeO2225TGd/Bl156aeZr+KAGiBBCCCHRwQ0QIYQQQqKj6CYwG2nhM1Fg0TQRt2hhyAQWUkdnzQTtU/1btR9+L2anRLOeiKsetNfAbJjlAhbIFBF55plnVH7llVdUtpExaM7D34WRNiJuUVKM4BJx77c9h6B5Au9pyJyJ5g/7DGF0F46fLWqK2UVt4c/OnTur3Lt3b5WtaeWBBx6QcmHdunUqo3paxB0LNP9akx7+vqY0gSGhOYzPojWBhbLIo1mmqqoq52dIYcA10pqlvvOd76iMc719+/ZOO4woPeqoo5xzOO64TjVHkxc+6/jMhuaeXe/yjeLyfd43JwYPHuwcY7ZmjMYLYV1PcF7iWhRyQ8kKNUCEEEIIiQ5ugAghhBASHdwAEUIIISQ6iu4DZEGbLtoRbSZo60fhw+dTZL8LbafW9o/HWasUo/9EKPw+lJ26lNTU1MhPfvITERGZOHGicw79r0LZd9HOjlmX7f3A7J12jNC3B32HrO8UPivoi2S/C/1YcBzwN9lroM0ZK4mLuM+D9VNDvxO8frn5eWFmcuyntaH7sqDbMfNlWBfxh9HaUGdr5/eB18drhMJt0ZfMPrPo72XHCefqq6++mql/5YJdV7Kmryj0d+O42DHGuV5dXa3yN7/5Tacd+tNhtYCxY8c67UK+WZg1Gv3eTjzxRO9nik0onUKoQns+aUkKTciH6OKLL1YZsz2LiPzqV7/K+Rn7Dsbr27UffS8HDhz46Z1tANQAEUIIISQ6uAEihBBCSHQU3QSWNYTUmhesGgzxZXW25iZfuHyoT3gNq1bG70JTgg37RjOMpVyKLLZp00auvPJKERE5/vjjnXPPP/+8ysuXL1d548aNTjs0IezcuVNlG3qM99SqPrHAbG1trcohswuq1u13+UJDbRFQNNmhmcSqmPFZsekOsB+o3rfh5eedd57Kd955Z87+FZM5c+bk/HvILIUmMPu7MSOvNTH51PVZ01XkC95zHFv7HKE51q4x+DsLUby1KQmZRkLh0oW49z63AZwTIq4p9u6771b59NNPd9phKoo//vGPefUJf1eoT01JKGt9PuOwcuVK5/ihhx5S2ZoVbSb8ekKmKHxX2TXg29/+tsqvvfaaytadwkfIpBZKe9OrVy/v5/JJyUENECGEEEKigxsgQgghhERHk0eBZQXVb1a968uMGVJbh1SMvmKo1pSxa9culdEEZrOQYgSCNRGUKnNuLur7ggVJRUSGDh2as7017a1fv17lNWvWqGwzu2ImVmsC9I2lVYNicUMsqod/F3HNkRjRZc2UqAoPqcXRLBQaO4yoQhOMSOkzCduip/XY59uXZRafexHXpBAyO/vmlT3G/oXuMX6vvac+k5397WiqtSZu+1sqhUI/f6FoppApDjM8d+rUSeWlS5c67SZMmNDIHrrPHprWmzoTdJqmaqYPZa3HZw/NSyIiDz74oMo2WhrB9fiJJ55wzmFGf18fbB9xHmE0nohrmnzqqae8fcL3JGbfD5necI6KuM/XKaec4v0umsAIIYQQQjLADRAhhBBCooMbIEIIIYRER9GN3uivIeKGoYZ8dtB2aO34aGcOhdP5Mm1aW6Ev5D7kv4N979atm9NuwYIFKls/i3LJBN2iRQv1i7FVzrdt26ZyyK7aunVrlb/4xS+qbP18fD4oIn6/Dvts4DV9IfEiblg8fgafOxE3dDNUPRz7bp8TzJyMz7n1JbHV1JuaU089NeffrW+IzyfBjgXek5AfEV7f3js8Rt8Ae/99Idb2etinUKZqvH6psuoWg5BfDvpw7dixw2mHcx3ncIisPkX//d//7RzjM4V+P5MmTcp0vVBqlFDGffQBamqSJAmuf7lYtGiRc4xjFloj27dvrzKmFxERefLJJ1W+4IILgv3NxeWXX+4cn3vuuSqHQtNxbmdl+/btzjH6VJ500kkNvl4IaoAIIYQQEh3cABFCCCEkOopiAkOzRCj75aGHHuq9BqqqQ+GpeP2Q+jxreG3IvOZT6VdVVTntsB8hFXy5YMO27bEPNFOGTAtofrKh9L77YU2FvoK1oc/heFlTbOfOnVXGZ8Oq2UO/y/fc2PuHIb+l4P/+7/9y/t2aePEYTYQdOnTwtrPzyvfs23uHpjOf2UzEvcehdjhuoYzOvjHLddycCJmlXn75ZZVtODOuwbYAdT5ZkzHb89y5c51zaJL2ZScPETLZhtqWsrDt3r17Zfbs2Tn7cckll6iMzyyaJS2Y2sNWT0Bzk12DRo0apXLIBIZceOGFKq9YscI5Z8PsCwkWMxbJ/hwyDJ4QQgghJAPcABFCCCEkOopiAgsVHkUVOZohLKGsrz7Vp1WB+SK/7Od9GWvt96IpDiOHbCbokAmsnDJBNxZUuYa8/a2qljQtTz/9dM6/W9MymqXw+b7//vuddv/4j/+osjVhYtFZfPatuQ3Phea67zM20hCPUYVuI+CwoK/NDu7DRk5Zk2AxqF8nskZchaLACh05E+Kaa65RedWqVc65KVOmNOraoYoAFnxWbNHQpuTtt9+WdevWiYjIdddd55y75ZZbVMZ5g2ZEew4jyqw5Ez8XKig6evRolf/5n//Zafetb31L5RkzZqh85plnOu1sBv5CYk2A1n3BRz4Zz6kBIoQQQkh0cANECCGEkOjgBogQQggh0VH0TNDWLoe2yFB4cNZsrr4w2VyfqydrNeOQjRn9DPr27eucC1WoryQfINI8wNQDaE+3Yc+++TJixAjn+Otf/7rK48ePd86h71BdXZ3KHTt29PYJsX4eODfR/8Fm9sbPDR06VGUM/xURmTVrVs5r5/rueiZPnuwco59LsWioP0OoPa45w4cPd86h38hNN93knLviiisyfff3vvc9ldHf7MYbb3Ta9e/fP9P1CgG+F2x18aakTZs28tWvflVERH7xi1845zA9AfbRzkOsAI/PPWb4FhFp27atytZHDp+Bu+66K6csItKuXTuV0a/zu9/9rvjAd1woNUFW7O/K6quXz3dTA0QIIYSQ6OAGiBBCCCHR0eQmMFTFhYpEYkguquVEXDV+KHurr6BjqAgr9s+q6X3FNUPh/LZ/oYJ+hBQDnINoosqqWrbcfvvtOeUQViWP/cA5Z9cLPMZQ+lAW+ayEslhjZl4sJClSfBPYnj17ZObMmSLyyfQBuPZhMWKb+RfXT/wtKIuIrFmzRuWxY8c65zD0GQttTps2zWn34x//WGUsqJr12ciXkNkP13hbsLdU2IoB8+bNUxkLatsCz5iGAX8XhseLuO+r0L3BtCShe4Omt5D5Mp/wc/tuRXObzQTtSzth1xT7bGeBGiBCCCGERAc3QIQQQgiJDm6ACCGEEBIdRfEB8pWgsIRSXKON0Nr6MBz29ddfV9mm9s8a0o6gjdX6Gbz55psqY7pua3vEvlufH2vfJaTY/PKXv1R54sSJKuPzLFL4cFbEzpF87PWFAP0wsOK9iOsThWvOySefXPR+Ie+8845s2LBBRET/X09NTY3K6EeFa6KI6+eB62DXrl2ddiNHjlT52GOPdc49++yzKmNl92XLljntTjnlFJXRj8j6L+G6WGy/HPQpOeecc4r6XVm5+eabneNHHnlEZSxrYd9V+J7Ed5K9h+iLY9876N+G17f+sPhM2RQXSGPXitD72L7vfT5AIV/erFADRAghhJDo4AaIEEIIIdFRFBMYZuG0atCsZqlLLrlE5d27dzvnMCwevysUEo/tQlXjUZ1nTWqtWrVSefDgwd7vQnW07RP2g5CmAE07WA3dVgnHeZY1C3CIUOoJPA6F0frOWbU7HofC6s8991yVH3zwQeccprY477zzVMYK2U0BZg/OCroCiIhs3rxZZczIjX8Xce8VPhsirtkLnw2bTRqfFWtiQ5oyHB1NYHfffbfKWIG9qbGh5HjvMYP2rbfe6rSbP3++yvZdWGg+//nPq3zaaacV7XtCZjN87kT8FSPyCb//RD8afQVCCCGEkGYGN0CEEEIIiY6imMD27dunckj1bYueIdZjvjmBqjn7+0O/mZBiE8o4ixEg1lSCYPSYzUCMoJq70FFlIdDMbM3YAwYM8J5DE9gNN9xQpN4VhzZt2gSPYwOj/ZrDWKJpFmXLqlWrVF64cKFzbunSpSpjkVsR1wyK7ydbxeBnP/tZzu+1biONnc8hc+jo0aOd46OPPjpnO+tekw/UABFCCCEkOrgBIoQQQkh0cANECCGEkOgoig8QVinu3bu3cw7DJIcOHeq9RihEvhDhb8UEw0LXr1/vnDvuuOOaujuEKDiv7rrrLuccztuOHTt6r1Eu1bV9hNYHTKGBodIi7u9qSp8lUlz+53/+p9RdKBj4PrXv1ssvv7xo31vod27oemeeeWama4TS3mSFs5wQQggh0cENECGEEEKiI8laJFREJEmS10Rk46c2JIWke5qm7T69WcPgWJYMjmflwLGsLAo+nhzLkpFpLBu0ASKEEEIIqQRoAiOEEEJIdHADRAghhJDoqOgNUJIkXZMkmZEkSXWSJCuSJBlV6j6R/EmS5OgkSRbDf7uTJLmx1P0iDYdzs/JIkmRDkiTLPpqbC0rdH5I/sYxlRfsAJUnSUUQ6pmm6KEmSQ0RkoYhclKbpyyXuGmkkSZK0EJEtIjI0TVM6GTYzODcrjyRJNojI4DRNa0vdF9I4YhnLitYApWm6LU3TRR/Je0SkWkQ6hz9FmglniMhabn6aJ5ybhJBSU9EbICRJkioRGSgiL5a2J6RAXCYij5S6E6TxcG5WDKmITEuSZGGSJNeWujOkUUQxlkUphVFuJElysIg8JiI3pmm6u9T9IY0jSZL9ReRLInJzqftCGgfnZkVxcpqmW5MkaS8izyRJsjJN09ml7hTJiyjGsuI1QEmS7CcfLrC/T9N0Yqn7QwrCMBFZlKbpjlJ3hOQP52Zlkabp1o/+XyMik0RkSGl7RPIllrGs6A1Q8mHFtV+KSHWapneXuj+kYFwuNH81azg3K4skSVp+5MwuSZK0FJGzRWR5aXtF8iGmsaz0KLBTRGSOiCwTkQ8++vOYNE2fKl2vSGNIkuQgEdkkIj3TNH2j1P0h+cG5WVkkSdJTPtQUiHzoWjE+TdPbStglkicxjWVFb4AIIYQQQnJR0SYwQgghhJBccANECCGEkOjgBogQQggh0cENECGEEEKigxsgQgghhEQHN0CEEEIIiQ5ugAghhBASHdwAEUIIISQ6/j+uPSzFCOLaLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(label[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 1.9555 - accuracy: 0.4874 - val_loss: 1.5283 - val_accuracy: 0.6206\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 1.2633 - accuracy: 0.6357 - val_loss: 1.0840 - val_accuracy: 0.6481\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.9525 - accuracy: 0.6868 - val_loss: 0.8617 - val_accuracy: 0.7141\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.7870 - accuracy: 0.7337 - val_loss: 0.7439 - val_accuracy: 0.7396\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6957 - accuracy: 0.7614 - val_loss: 0.6804 - val_accuracy: 0.7696\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6500 - accuracy: 0.7756 - val_loss: 0.6516 - val_accuracy: 0.7716\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6251 - accuracy: 0.7850 - val_loss: 0.6331 - val_accuracy: 0.7826\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6039 - accuracy: 0.7912 - val_loss: 0.6160 - val_accuracy: 0.7841\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6086 - accuracy: 0.7902 - val_loss: 0.6167 - val_accuracy: 0.7828\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6016 - accuracy: 0.7898 - val_loss: 0.6242 - val_accuracy: 0.7835\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5963 - accuracy: 0.7928 - val_loss: 0.6341 - val_accuracy: 0.7763\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6096 - accuracy: 0.7850 - val_loss: 0.6403 - val_accuracy: 0.7648\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6175 - accuracy: 0.7807 - val_loss: 0.6334 - val_accuracy: 0.7655\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6273 - accuracy: 0.7732 - val_loss: 0.6770 - val_accuracy: 0.7491\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6295 - accuracy: 0.7750 - val_loss: 0.6519 - val_accuracy: 0.7789\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6205 - accuracy: 0.7765 - val_loss: 0.6695 - val_accuracy: 0.7518\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6267 - accuracy: 0.7782 - val_loss: 0.6524 - val_accuracy: 0.7708\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.6423 - accuracy: 0.7721 - val_loss: 0.6534 - val_accuracy: 0.7626\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6584 - accuracy: 0.7548 - val_loss: 0.6939 - val_accuracy: 0.7354\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6580 - accuracy: 0.7607 - val_loss: 0.6808 - val_accuracy: 0.7509\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6557 - accuracy: 0.7574 - val_loss: 0.6925 - val_accuracy: 0.7306\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.6528 - accuracy: 0.7557 - val_loss: 0.6603 - val_accuracy: 0.7405\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.6367 - accuracy: 0.7617 - val_loss: 0.6568 - val_accuracy: 0.7552\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6415 - accuracy: 0.7617 - val_loss: 0.6546 - val_accuracy: 0.7591\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6396 - accuracy: 0.7623 - val_loss: 0.6679 - val_accuracy: 0.7650\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.6484 - accuracy: 0.7622 - val_loss: 0.6724 - val_accuracy: 0.7410\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6400 - accuracy: 0.7624 - val_loss: 0.7095 - val_accuracy: 0.7440\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6522 - accuracy: 0.7572 - val_loss: 0.6890 - val_accuracy: 0.7414\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.6489 - accuracy: 0.7585 - val_loss: 0.6655 - val_accuracy: 0.7590\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6467 - accuracy: 0.7649 - val_loss: 0.6805 - val_accuracy: 0.7441\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6597 - accuracy: 0.7584 - val_loss: 0.7156 - val_accuracy: 0.7279\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6792 - accuracy: 0.7508 - val_loss: 0.7216 - val_accuracy: 0.7422\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6728 - accuracy: 0.7490 - val_loss: 0.6721 - val_accuracy: 0.7602\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6422 - accuracy: 0.7667 - val_loss: 0.6429 - val_accuracy: 0.7776\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.6346 - accuracy: 0.7737 - val_loss: 0.6567 - val_accuracy: 0.7656\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6525 - accuracy: 0.7577 - val_loss: 0.6622 - val_accuracy: 0.7517\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6414 - accuracy: 0.7609 - val_loss: 0.6730 - val_accuracy: 0.7639\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.6380 - accuracy: 0.7652 - val_loss: 0.6647 - val_accuracy: 0.7490\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6315 - accuracy: 0.7668 - val_loss: 0.6879 - val_accuracy: 0.7562\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6368 - accuracy: 0.7655 - val_loss: 0.6912 - val_accuracy: 0.7502\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.6598 - accuracy: 0.7578 - val_loss: 0.6936 - val_accuracy: 0.7561\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6746 - accuracy: 0.7538 - val_loss: 0.6706 - val_accuracy: 0.7607\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.6314 - accuracy: 0.7718 - val_loss: 0.6469 - val_accuracy: 0.7640\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6227 - accuracy: 0.7721 - val_loss: 0.6558 - val_accuracy: 0.7548\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6529 - accuracy: 0.7494 - val_loss: 0.7463 - val_accuracy: 0.7042\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6488 - accuracy: 0.7583 - val_loss: 0.6769 - val_accuracy: 0.7380\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6175 - accuracy: 0.7701 - val_loss: 0.6664 - val_accuracy: 0.7443\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.6279 - accuracy: 0.7570 - val_loss: 0.6603 - val_accuracy: 0.7348\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6161 - accuracy: 0.7679 - val_loss: 0.6531 - val_accuracy: 0.7594\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6077 - accuracy: 0.7769 - val_loss: 0.6227 - val_accuracy: 0.7764\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.6304 - accuracy: 0.7690 - val_loss: 0.6854 - val_accuracy: 0.7580\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.6304 - accuracy: 0.7637 - val_loss: 0.6483 - val_accuracy: 0.7526\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6288 - accuracy: 0.7677 - val_loss: 0.6483 - val_accuracy: 0.7555\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6437 - accuracy: 0.7587 - val_loss: 0.6705 - val_accuracy: 0.7519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6233 - accuracy: 0.7742 - val_loss: 0.6216 - val_accuracy: 0.7813\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.6218 - accuracy: 0.7732 - val_loss: 0.6521 - val_accuracy: 0.7446\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.6288 - accuracy: 0.7703 - val_loss: 0.6756 - val_accuracy: 0.7439\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6212 - accuracy: 0.7737 - val_loss: 0.6786 - val_accuracy: 0.7576\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6391 - accuracy: 0.7658 - val_loss: 0.7000 - val_accuracy: 0.7161\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.6289 - accuracy: 0.7692 - val_loss: 0.6689 - val_accuracy: 0.7473\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6318 - accuracy: 0.7603 - val_loss: 0.6428 - val_accuracy: 0.7656\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6150 - accuracy: 0.7702 - val_loss: 0.6722 - val_accuracy: 0.7563\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6054 - accuracy: 0.7769 - val_loss: 0.6748 - val_accuracy: 0.7449\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.6020 - accuracy: 0.7798 - val_loss: 0.6325 - val_accuracy: 0.7656\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5943 - accuracy: 0.7780 - val_loss: 0.6186 - val_accuracy: 0.7796\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6009 - accuracy: 0.7815 - val_loss: 0.6292 - val_accuracy: 0.7626\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5957 - accuracy: 0.7808 - val_loss: 0.6108 - val_accuracy: 0.7827\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5990 - accuracy: 0.7774 - val_loss: 0.6303 - val_accuracy: 0.7748\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5977 - accuracy: 0.7835 - val_loss: 0.6286 - val_accuracy: 0.7753\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6147 - accuracy: 0.7728 - val_loss: 0.6370 - val_accuracy: 0.7589\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6266 - accuracy: 0.7646 - val_loss: 0.6353 - val_accuracy: 0.7661\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6112 - accuracy: 0.7771 - val_loss: 0.6197 - val_accuracy: 0.7816\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6004 - accuracy: 0.7754 - val_loss: 0.6422 - val_accuracy: 0.7551\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5991 - accuracy: 0.7795 - val_loss: 0.6664 - val_accuracy: 0.7611\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.6159 - accuracy: 0.7778 - val_loss: 0.6455 - val_accuracy: 0.7703\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.6142 - accuracy: 0.7781 - val_loss: 0.6932 - val_accuracy: 0.7302\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6278 - accuracy: 0.7648 - val_loss: 0.6539 - val_accuracy: 0.7609\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6400 - accuracy: 0.7624 - val_loss: 0.6800 - val_accuracy: 0.7354\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6187 - accuracy: 0.7763 - val_loss: 0.6402 - val_accuracy: 0.7743\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.6224 - accuracy: 0.7749 - val_loss: 0.6846 - val_accuracy: 0.7518\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6353 - accuracy: 0.7634 - val_loss: 0.6535 - val_accuracy: 0.7697\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5993 - accuracy: 0.7833 - val_loss: 0.6046 - val_accuracy: 0.7881\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6207 - accuracy: 0.7689 - val_loss: 0.6249 - val_accuracy: 0.7723\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5900 - accuracy: 0.7856 - val_loss: 0.6203 - val_accuracy: 0.7717\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5907 - accuracy: 0.7811 - val_loss: 0.6083 - val_accuracy: 0.7676\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5752 - accuracy: 0.7880 - val_loss: 0.6013 - val_accuracy: 0.7683\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5727 - accuracy: 0.7869 - val_loss: 0.5972 - val_accuracy: 0.7826\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.5694 - accuracy: 0.7946 - val_loss: 0.5964 - val_accuracy: 0.7901\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.5761 - accuracy: 0.7898 - val_loss: 0.5911 - val_accuracy: 0.7852\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.5632 - accuracy: 0.7945 - val_loss: 0.5987 - val_accuracy: 0.7813\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.5752 - accuracy: 0.7850 - val_loss: 0.6171 - val_accuracy: 0.7577\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5803 - accuracy: 0.7856 - val_loss: 0.6381 - val_accuracy: 0.7682\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5867 - accuracy: 0.7780 - val_loss: 0.6150 - val_accuracy: 0.7849\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.6058 - accuracy: 0.7729 - val_loss: 0.6354 - val_accuracy: 0.7382\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.5909 - accuracy: 0.7732 - val_loss: 0.6027 - val_accuracy: 0.7664\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.5967 - accuracy: 0.7728 - val_loss: 0.6227 - val_accuracy: 0.7621\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.6054 - accuracy: 0.7717 - val_loss: 0.6170 - val_accuracy: 0.7776\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.5783 - accuracy: 0.7850 - val_loss: 0.6072 - val_accuracy: 0.7609\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.5877 - accuracy: 0.7814 - val_loss: 0.6093 - val_accuracy: 0.7635\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.5761 - accuracy: 0.7867 - val_loss: 0.5985 - val_accuracy: 0.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6fb27a400>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_10 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 182,660\n",
      "Trainable params: 182,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "model1.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
    "model1.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model1.add(tf.keras.layers.Dense(50, activation='sigmoid'))\n",
    "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 2.1270 - accuracy: 0.4060 - val_loss: 1.8194 - val_accuracy: 0.5127\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 1.5119 - accuracy: 0.5868 - val_loss: 1.2384 - val_accuracy: 0.6553\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 1.0841 - accuracy: 0.6720 - val_loss: 0.9318 - val_accuracy: 0.7119\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.8620 - accuracy: 0.7188 - val_loss: 0.7745 - val_accuracy: 0.7357\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.7470 - accuracy: 0.7369 - val_loss: 0.6921 - val_accuracy: 0.7526\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.6816 - accuracy: 0.7532 - val_loss: 0.6424 - val_accuracy: 0.7660\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.6381 - accuracy: 0.7692 - val_loss: 0.6066 - val_accuracy: 0.7783\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.6049 - accuracy: 0.7822 - val_loss: 0.5768 - val_accuracy: 0.7929\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.5767 - accuracy: 0.7947 - val_loss: 0.5537 - val_accuracy: 0.8011\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.5544 - accuracy: 0.8030 - val_loss: 0.5348 - val_accuracy: 0.8063\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.5353 - accuracy: 0.8104 - val_loss: 0.5191 - val_accuracy: 0.8133\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.5176 - accuracy: 0.8166 - val_loss: 0.5044 - val_accuracy: 0.8199\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.5014 - accuracy: 0.8222 - val_loss: 0.4926 - val_accuracy: 0.8251\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4902 - accuracy: 0.8267 - val_loss: 0.4813 - val_accuracy: 0.8290\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4775 - accuracy: 0.8313 - val_loss: 0.4740 - val_accuracy: 0.8315\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4717 - accuracy: 0.8340 - val_loss: 0.4666 - val_accuracy: 0.8309\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4604 - accuracy: 0.8367 - val_loss: 0.4600 - val_accuracy: 0.8342\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4531 - accuracy: 0.8404 - val_loss: 0.4540 - val_accuracy: 0.8349\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4462 - accuracy: 0.8421 - val_loss: 0.4474 - val_accuracy: 0.8373\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4363 - accuracy: 0.8461 - val_loss: 0.4427 - val_accuracy: 0.8395\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.4345 - accuracy: 0.8456 - val_loss: 0.4367 - val_accuracy: 0.8388\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4267 - accuracy: 0.8490 - val_loss: 0.4309 - val_accuracy: 0.8410\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4187 - accuracy: 0.8501 - val_loss: 0.4265 - val_accuracy: 0.8415\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.4140 - accuracy: 0.8527 - val_loss: 0.4245 - val_accuracy: 0.8423\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4104 - accuracy: 0.8551 - val_loss: 0.4186 - val_accuracy: 0.8461\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4043 - accuracy: 0.8556 - val_loss: 0.4158 - val_accuracy: 0.8465\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3974 - accuracy: 0.8587 - val_loss: 0.4100 - val_accuracy: 0.8488\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3938 - accuracy: 0.8604 - val_loss: 0.4060 - val_accuracy: 0.8505\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3880 - accuracy: 0.8614 - val_loss: 0.4047 - val_accuracy: 0.8516\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3842 - accuracy: 0.8632 - val_loss: 0.3996 - val_accuracy: 0.8517\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3796 - accuracy: 0.8657 - val_loss: 0.3963 - val_accuracy: 0.8551\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3738 - accuracy: 0.8673 - val_loss: 0.3914 - val_accuracy: 0.8564\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3688 - accuracy: 0.8688 - val_loss: 0.3894 - val_accuracy: 0.8580\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3658 - accuracy: 0.8698 - val_loss: 0.3856 - val_accuracy: 0.8572\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3607 - accuracy: 0.8719 - val_loss: 0.3835 - val_accuracy: 0.8599\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3580 - accuracy: 0.8732 - val_loss: 0.3810 - val_accuracy: 0.8599\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3542 - accuracy: 0.8740 - val_loss: 0.3780 - val_accuracy: 0.8624\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3501 - accuracy: 0.8747 - val_loss: 0.3780 - val_accuracy: 0.8612\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3468 - accuracy: 0.8756 - val_loss: 0.3739 - val_accuracy: 0.8629\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3436 - accuracy: 0.8787 - val_loss: 0.3720 - val_accuracy: 0.8612\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3398 - accuracy: 0.8777 - val_loss: 0.3681 - val_accuracy: 0.8637\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3359 - accuracy: 0.8805 - val_loss: 0.3727 - val_accuracy: 0.8624\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3319 - accuracy: 0.8820 - val_loss: 0.3693 - val_accuracy: 0.8656\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3287 - accuracy: 0.8833 - val_loss: 0.3638 - val_accuracy: 0.8656\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3261 - accuracy: 0.8824 - val_loss: 0.3608 - val_accuracy: 0.8681\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3212 - accuracy: 0.8849 - val_loss: 0.3587 - val_accuracy: 0.8688\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3184 - accuracy: 0.8872 - val_loss: 0.3575 - val_accuracy: 0.8681\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3153 - accuracy: 0.8877 - val_loss: 0.3562 - val_accuracy: 0.8689\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3117 - accuracy: 0.8884 - val_loss: 0.3546 - val_accuracy: 0.8703\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3077 - accuracy: 0.8896 - val_loss: 0.3498 - val_accuracy: 0.8735\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3068 - accuracy: 0.8910 - val_loss: 0.3523 - val_accuracy: 0.8708\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3027 - accuracy: 0.8914 - val_loss: 0.3509 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2992 - accuracy: 0.8928 - val_loss: 0.3447 - val_accuracy: 0.8726\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2961 - accuracy: 0.8932 - val_loss: 0.3479 - val_accuracy: 0.8735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2937 - accuracy: 0.8939 - val_loss: 0.3421 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2922 - accuracy: 0.8956 - val_loss: 0.3435 - val_accuracy: 0.8748\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2872 - accuracy: 0.8967 - val_loss: 0.3410 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2861 - accuracy: 0.8970 - val_loss: 0.3422 - val_accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2810 - accuracy: 0.8989 - val_loss: 0.3399 - val_accuracy: 0.8755\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2797 - accuracy: 0.8999 - val_loss: 0.3365 - val_accuracy: 0.8768\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2773 - accuracy: 0.9006 - val_loss: 0.3366 - val_accuracy: 0.8762\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2745 - accuracy: 0.9010 - val_loss: 0.3372 - val_accuracy: 0.8795\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2721 - accuracy: 0.9017 - val_loss: 0.3360 - val_accuracy: 0.8784\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2684 - accuracy: 0.9029 - val_loss: 0.3355 - val_accuracy: 0.8775\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2648 - accuracy: 0.9056 - val_loss: 0.3334 - val_accuracy: 0.8801\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2632 - accuracy: 0.9059 - val_loss: 0.3320 - val_accuracy: 0.8787\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2617 - accuracy: 0.9069 - val_loss: 0.3344 - val_accuracy: 0.8820\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2575 - accuracy: 0.9070 - val_loss: 0.3321 - val_accuracy: 0.8801\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2549 - accuracy: 0.9082 - val_loss: 0.3354 - val_accuracy: 0.8789\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2538 - accuracy: 0.9077 - val_loss: 0.3315 - val_accuracy: 0.8815\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2497 - accuracy: 0.9102 - val_loss: 0.3334 - val_accuracy: 0.8824\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2466 - accuracy: 0.9108 - val_loss: 0.3337 - val_accuracy: 0.8822\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2456 - accuracy: 0.9117 - val_loss: 0.3308 - val_accuracy: 0.8816\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2423 - accuracy: 0.9122 - val_loss: 0.3320 - val_accuracy: 0.8814\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2386 - accuracy: 0.9152 - val_loss: 0.3416 - val_accuracy: 0.8796\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2402 - accuracy: 0.9132 - val_loss: 0.3307 - val_accuracy: 0.8825\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2360 - accuracy: 0.9148 - val_loss: 0.3259 - val_accuracy: 0.8827\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2332 - accuracy: 0.9162 - val_loss: 0.3254 - val_accuracy: 0.8827\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2296 - accuracy: 0.9177 - val_loss: 0.3328 - val_accuracy: 0.8817\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2298 - accuracy: 0.9173 - val_loss: 0.3320 - val_accuracy: 0.8840\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2278 - accuracy: 0.9170 - val_loss: 0.3240 - val_accuracy: 0.8835\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2251 - accuracy: 0.9190 - val_loss: 0.3272 - val_accuracy: 0.8828\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2207 - accuracy: 0.9215 - val_loss: 0.3288 - val_accuracy: 0.8828\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2182 - accuracy: 0.9218 - val_loss: 0.3314 - val_accuracy: 0.8856\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2180 - accuracy: 0.9221 - val_loss: 0.3211 - val_accuracy: 0.8836\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2139 - accuracy: 0.9231 - val_loss: 0.3249 - val_accuracy: 0.8856\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2139 - accuracy: 0.9231 - val_loss: 0.3266 - val_accuracy: 0.8820\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2100 - accuracy: 0.9257 - val_loss: 0.3239 - val_accuracy: 0.8850\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2087 - accuracy: 0.9256 - val_loss: 0.3283 - val_accuracy: 0.8853\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2073 - accuracy: 0.9257 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2050 - accuracy: 0.9259 - val_loss: 0.3271 - val_accuracy: 0.8839\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2021 - accuracy: 0.9279 - val_loss: 0.3242 - val_accuracy: 0.8858\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1994 - accuracy: 0.9280 - val_loss: 0.3385 - val_accuracy: 0.8836\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1980 - accuracy: 0.9295 - val_loss: 0.3257 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1948 - accuracy: 0.9302 - val_loss: 0.3305 - val_accuracy: 0.8851\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1938 - accuracy: 0.9314 - val_loss: 0.3302 - val_accuracy: 0.8872\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1909 - accuracy: 0.9315 - val_loss: 0.3288 - val_accuracy: 0.8851\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1887 - accuracy: 0.9323 - val_loss: 0.3261 - val_accuracy: 0.8855\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1881 - accuracy: 0.9327 - val_loss: 0.3371 - val_accuracy: 0.8872\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1832 - accuracy: 0.9350 - val_loss: 0.3340 - val_accuracy: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6f85e3080>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_11 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 185,796\n",
      "Trainable params: 184,228\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x1f6fad9e780>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "model2.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
    "model2.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model2.add(tf.keras.layers.Dense(50, activation='sigmoid'))\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "tf.keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 2.1469 - val_loss: 1.8537\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 1.5510 - val_loss: 1.2865\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 1.1399 - val_loss: 0.9874\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.9108 - val_loss: 0.8115\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.7746 - val_loss: 0.7106\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.6960 - val_loss: 0.6527\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.6465 - val_loss: 0.6124\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.6105 - val_loss: 0.5811\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.5804 - val_loss: 0.5558\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.5567 - val_loss: 0.5360\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.5368 - val_loss: 0.5198\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5178 - val_loss: 0.5042\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5005 - val_loss: 0.4911\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4893 - val_loss: 0.4801\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4749 - val_loss: 0.4717\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4689 - val_loss: 0.4641\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4583 - val_loss: 0.4562\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4498 - val_loss: 0.4495\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4433 - val_loss: 0.4445\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4335 - val_loss: 0.4390\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4309 - val_loss: 0.4328\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4234 - val_loss: 0.4274\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4159 - val_loss: 0.4224\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4111 - val_loss: 0.4198\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4071 - val_loss: 0.4155\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4011 - val_loss: 0.4120\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3956 - val_loss: 0.4056\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3920 - val_loss: 0.4020\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3855 - val_loss: 0.4012\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3820 - val_loss: 0.3954\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3775 - val_loss: 0.3937\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3724 - val_loss: 0.3890\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3679 - val_loss: 0.3855\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3660 - val_loss: 0.3833\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3598 - val_loss: 0.3804\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3562 - val_loss: 0.3777\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3538 - val_loss: 0.3752\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3490 - val_loss: 0.3744\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3459 - val_loss: 0.3705\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3436 - val_loss: 0.3690\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3403 - val_loss: 0.3643\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3364 - val_loss: 0.3690\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3331 - val_loss: 0.3637\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3291 - val_loss: 0.3606\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3262 - val_loss: 0.3568\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3225 - val_loss: 0.3547\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3192 - val_loss: 0.3534\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3161 - val_loss: 0.3517\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3130 - val_loss: 0.3515\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3087 - val_loss: 0.3473\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3080 - val_loss: 0.3495\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3036 - val_loss: 0.3458\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3008 - val_loss: 0.3415\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2982 - val_loss: 0.3437\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2960 - val_loss: 0.3384\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2933 - val_loss: 0.3413\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2897 - val_loss: 0.3375\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2901 - val_loss: 0.3380\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2844 - val_loss: 0.3358\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2832 - val_loss: 0.3327\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2803 - val_loss: 0.3337\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2769 - val_loss: 0.3335\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2753 - val_loss: 0.3316\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2698 - val_loss: 0.3317\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2683 - val_loss: 0.3287\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2669 - val_loss: 0.3308\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2650 - val_loss: 0.3302\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2611 - val_loss: 0.3276\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2587 - val_loss: 0.3284\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2565 - val_loss: 0.3285\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2525 - val_loss: 0.3300\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2507 - val_loss: 0.3278\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2493 - val_loss: 0.3256\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2466 - val_loss: 0.3260\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2442 - val_loss: 0.3379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2433 - val_loss: 0.3237\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2399 - val_loss: 0.3230\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2385 - val_loss: 0.3210\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2350 - val_loss: 0.3254\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2341 - val_loss: 0.3294\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2318 - val_loss: 0.3220\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2292 - val_loss: 0.3232\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2251 - val_loss: 0.3228\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2247 - val_loss: 0.3258\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2202 - val_loss: 0.3222\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2181 - val_loss: 0.3232\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2194 - val_loss: 0.3222\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2160 - val_loss: 0.3254\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2145 - val_loss: 0.3248\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2122 - val_loss: 0.3243\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2111 - val_loss: 0.3207\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2092 - val_loss: 0.3206\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2049 - val_loss: 0.3306\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2044 - val_loss: 0.3214\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2019 - val_loss: 0.3260\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2004 - val_loss: 0.3231\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1973 - val_loss: 0.3249\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1955 - val_loss: 0.3241\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1951 - val_loss: 0.3296\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1907 - val_loss: 0.3312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6faeb6da0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_24 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 185,796\n",
      "Trainable params: 184,228\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x1f7061f4908>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "model3.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model3.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "tf.keras.optimizers.SGD(learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_23 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 92,746\n",
      "Trainable params: 91,178\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1828 - accuracy: 0.9353 - val_loss: 0.3313 - val_accuracy: 0.8865\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1837 - accuracy: 0.9346 - val_loss: 0.3357 - val_accuracy: 0.8817\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1813 - accuracy: 0.9353 - val_loss: 0.3312 - val_accuracy: 0.8860\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1792 - accuracy: 0.9362 - val_loss: 0.3308 - val_accuracy: 0.8864\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1766 - accuracy: 0.9371 - val_loss: 0.3345 - val_accuracy: 0.8855\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1749 - accuracy: 0.9370 - val_loss: 0.3376 - val_accuracy: 0.8865\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1738 - accuracy: 0.9374 - val_loss: 0.3450 - val_accuracy: 0.8838\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1718 - accuracy: 0.9380 - val_loss: 0.3371 - val_accuracy: 0.8847\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1698 - accuracy: 0.9405 - val_loss: 0.3394 - val_accuracy: 0.8824\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1676 - accuracy: 0.9407 - val_loss: 0.3400 - val_accuracy: 0.8887\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1682 - accuracy: 0.9407 - val_loss: 0.3376 - val_accuracy: 0.8872\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1648 - accuracy: 0.9404 - val_loss: 0.3363 - val_accuracy: 0.8865\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1605 - accuracy: 0.9433 - val_loss: 0.3432 - val_accuracy: 0.8872\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1607 - accuracy: 0.9425 - val_loss: 0.3416 - val_accuracy: 0.8866\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1578 - accuracy: 0.9438 - val_loss: 0.3419 - val_accuracy: 0.8847\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1584 - accuracy: 0.9437 - val_loss: 0.3518 - val_accuracy: 0.8818\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1561 - accuracy: 0.9440 - val_loss: 0.3577 - val_accuracy: 0.8883\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1536 - accuracy: 0.9453 - val_loss: 0.3490 - val_accuracy: 0.8865\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1532 - accuracy: 0.9452 - val_loss: 0.3478 - val_accuracy: 0.8883\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1510 - accuracy: 0.9466 - val_loss: 0.3520 - val_accuracy: 0.8853\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1510 - accuracy: 0.9466 - val_loss: 0.3508 - val_accuracy: 0.8868\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1492 - accuracy: 0.9470 - val_loss: 0.3464 - val_accuracy: 0.8857\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1462 - accuracy: 0.9478 - val_loss: 0.3474 - val_accuracy: 0.8883\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1427 - accuracy: 0.9491 - val_loss: 0.3459 - val_accuracy: 0.8876\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1454 - accuracy: 0.9485 - val_loss: 0.3535 - val_accuracy: 0.8870\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1431 - accuracy: 0.9498 - val_loss: 0.3543 - val_accuracy: 0.8904\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1391 - accuracy: 0.9510 - val_loss: 0.3479 - val_accuracy: 0.8855\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1421 - accuracy: 0.9496 - val_loss: 0.3504 - val_accuracy: 0.8882\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1404 - accuracy: 0.9500 - val_loss: 0.3675 - val_accuracy: 0.8829\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1371 - accuracy: 0.9513 - val_loss: 0.3494 - val_accuracy: 0.8877\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1351 - accuracy: 0.9522 - val_loss: 0.3605 - val_accuracy: 0.8857\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1321 - accuracy: 0.9531 - val_loss: 0.3558 - val_accuracy: 0.8900\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1318 - accuracy: 0.9537 - val_loss: 0.3635 - val_accuracy: 0.8867\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1312 - accuracy: 0.9539 - val_loss: 0.3632 - val_accuracy: 0.8855\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1304 - accuracy: 0.9536 - val_loss: 0.3618 - val_accuracy: 0.8866\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1271 - accuracy: 0.9552 - val_loss: 0.3625 - val_accuracy: 0.8856\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1272 - accuracy: 0.9556 - val_loss: 0.3561 - val_accuracy: 0.8879\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1273 - accuracy: 0.9544 - val_loss: 0.3694 - val_accuracy: 0.8844\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1228 - accuracy: 0.9579 - val_loss: 0.3735 - val_accuracy: 0.8825\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1237 - accuracy: 0.9560 - val_loss: 0.3665 - val_accuracy: 0.8855\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1242 - accuracy: 0.9569 - val_loss: 0.3664 - val_accuracy: 0.8847\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1233 - accuracy: 0.9564 - val_loss: 0.3678 - val_accuracy: 0.8864\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1194 - accuracy: 0.9582 - val_loss: 0.3882 - val_accuracy: 0.8845\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1192 - accuracy: 0.9574 - val_loss: 0.3792 - val_accuracy: 0.8843\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1190 - accuracy: 0.9578 - val_loss: 0.3790 - val_accuracy: 0.8812\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1184 - accuracy: 0.9584 - val_loss: 0.3744 - val_accuracy: 0.8856\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1153 - accuracy: 0.9587 - val_loss: 0.3800 - val_accuracy: 0.8814\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1140 - accuracy: 0.9603 - val_loss: 0.3835 - val_accuracy: 0.8850\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1158 - accuracy: 0.9593 - val_loss: 0.3846 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1121 - accuracy: 0.9612 - val_loss: 0.3706 - val_accuracy: 0.8859\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1115 - accuracy: 0.9613 - val_loss: 0.3849 - val_accuracy: 0.8847\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1117 - accuracy: 0.9601 - val_loss: 0.3804 - val_accuracy: 0.8825\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1108 - accuracy: 0.9618 - val_loss: 0.3737 - val_accuracy: 0.8866\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1082 - accuracy: 0.9619 - val_loss: 0.3839 - val_accuracy: 0.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1061 - accuracy: 0.9626 - val_loss: 0.3877 - val_accuracy: 0.8858\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1060 - accuracy: 0.9630 - val_loss: 0.3890 - val_accuracy: 0.8823\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1048 - accuracy: 0.9635 - val_loss: 0.3873 - val_accuracy: 0.8824\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1060 - accuracy: 0.9634 - val_loss: 0.3874 - val_accuracy: 0.8847\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1019 - accuracy: 0.9641 - val_loss: 0.3922 - val_accuracy: 0.8842\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1030 - accuracy: 0.9639 - val_loss: 0.3899 - val_accuracy: 0.8855\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1018 - accuracy: 0.9639 - val_loss: 0.3953 - val_accuracy: 0.8841\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0998 - accuracy: 0.9655 - val_loss: 0.4044 - val_accuracy: 0.8854\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1003 - accuracy: 0.9652 - val_loss: 0.4002 - val_accuracy: 0.8811\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0991 - accuracy: 0.9658 - val_loss: 0.4033 - val_accuracy: 0.8841\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0968 - accuracy: 0.9663 - val_loss: 0.4036 - val_accuracy: 0.8844\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0969 - accuracy: 0.9667 - val_loss: 0.3994 - val_accuracy: 0.8864\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0964 - accuracy: 0.9661 - val_loss: 0.3976 - val_accuracy: 0.8845\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0949 - accuracy: 0.9661 - val_loss: 0.4062 - val_accuracy: 0.8849\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0948 - accuracy: 0.9670 - val_loss: 0.4027 - val_accuracy: 0.8873\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0919 - accuracy: 0.9679 - val_loss: 0.4077 - val_accuracy: 0.8825\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0899 - accuracy: 0.9698 - val_loss: 0.4042 - val_accuracy: 0.8841\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0916 - accuracy: 0.9679 - val_loss: 0.4034 - val_accuracy: 0.8847\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0924 - accuracy: 0.9680 - val_loss: 0.4015 - val_accuracy: 0.8840\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0897 - accuracy: 0.9688 - val_loss: 0.4133 - val_accuracy: 0.8833\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0877 - accuracy: 0.9691 - val_loss: 0.4277 - val_accuracy: 0.8810\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0902 - accuracy: 0.9690 - val_loss: 0.4151 - val_accuracy: 0.8854\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0887 - accuracy: 0.9689 - val_loss: 0.4077 - val_accuracy: 0.8850\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0874 - accuracy: 0.9698 - val_loss: 0.4088 - val_accuracy: 0.8836\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0854 - accuracy: 0.9703 - val_loss: 0.4218 - val_accuracy: 0.8801\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0858 - accuracy: 0.9696 - val_loss: 0.4225 - val_accuracy: 0.8814\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0860 - accuracy: 0.9698 - val_loss: 0.4180 - val_accuracy: 0.8834\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0849 - accuracy: 0.9702 - val_loss: 0.4211 - val_accuracy: 0.8826\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0857 - accuracy: 0.9704 - val_loss: 0.4159 - val_accuracy: 0.8841\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0831 - accuracy: 0.9705 - val_loss: 0.4221 - val_accuracy: 0.8824\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0819 - accuracy: 0.9715 - val_loss: 0.4170 - val_accuracy: 0.8840\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0817 - accuracy: 0.9718 - val_loss: 0.4140 - val_accuracy: 0.8860\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0813 - accuracy: 0.9716 - val_loss: 0.4189 - val_accuracy: 0.8839\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0793 - accuracy: 0.9726 - val_loss: 0.4185 - val_accuracy: 0.8853\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0805 - accuracy: 0.9718 - val_loss: 0.4248 - val_accuracy: 0.8806\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0773 - accuracy: 0.9730 - val_loss: 0.4229 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0793 - accuracy: 0.9727 - val_loss: 0.4236 - val_accuracy: 0.8812\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0769 - accuracy: 0.9735 - val_loss: 0.4232 - val_accuracy: 0.8835\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0761 - accuracy: 0.9738 - val_loss: 0.4531 - val_accuracy: 0.8776\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0754 - accuracy: 0.9736 - val_loss: 0.4226 - val_accuracy: 0.8838\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.4350 - val_accuracy: 0.8795\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0756 - accuracy: 0.9740 - val_loss: 0.4364 - val_accuracy: 0.8802\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0731 - accuracy: 0.9751 - val_loss: 0.4279 - val_accuracy: 0.8853\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0725 - accuracy: 0.9744 - val_loss: 0.4303 - val_accuracy: 0.8831\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0731 - accuracy: 0.9752 - val_loss: 0.4539 - val_accuracy: 0.8806\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0704 - accuracy: 0.9761 - val_loss: 0.4393 - val_accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6facd3160>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
